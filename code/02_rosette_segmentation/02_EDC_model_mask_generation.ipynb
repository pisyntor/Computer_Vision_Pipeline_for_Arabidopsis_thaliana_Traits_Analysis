{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import cv2\n",
    "import torch\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from segmentation_models_pytorch.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_noise_isPresent(mask):\n",
    "\n",
    "    contours_org, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    count_org = len(contours_org)\n",
    "    if count_org == 1:\n",
    "        return True\n",
    "\n",
    "    # Create a kernel (structuring element) for dilation\n",
    "    # A 5x5 matrix of ones will be used here\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    # Apply dilation to the image\n",
    "\n",
    "    dilated_mask = cv2.dilate(mask.copy(), kernel, iterations=1)\n",
    "    contours_dilated, _ = cv2.findContours(dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    count_dilated = len(contours_dilated)\n",
    "    if count_dilated >1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def new_remove_noise(mask,threshold=0.1):\n",
    "\n",
    "    noise_preset = check_if_noise_isPresent(mask)\n",
    "    if noise_preset == False:\n",
    "        return mask\n",
    "\n",
    "    noise_removed_mask = np.zeros_like(mask)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours)>0:\n",
    "        largest_contour_area = cv2.contourArea(max(contours, key=cv2.contourArea))\n",
    "\n",
    "        for contour in contours:\n",
    "            area_contour = cv2.contourArea(contour)\n",
    "            # pdb.set_trace()\n",
    "            if area_contour < (largest_contour_area * threshold):\n",
    "                cv2.drawContours(noise_removed_mask, [contour], -1, 255, -1)\n",
    "\n",
    "        cleaned_mask = cv2.subtract(mask, noise_removed_mask)\n",
    "\n",
    "        return cleaned_mask\n",
    "    else:\n",
    "        return mask\n",
    "\n",
    "\n",
    "def get_area_of_leaf(orginal_image_mask):\n",
    "\n",
    "    orginal_image = orginal_image_mask\n",
    "\n",
    "    if len(orginal_image.shape) != 2:\n",
    "        orginal_image = cv2.cvtColor(orginal_image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    black_mask = np.zeros_like(orginal_image)\n",
    "    orginal_image[orginal_image>50]=255\n",
    "    orginal_image[orginal_image<50]=0\n",
    "\n",
    "    contours, _ = cv2.findContours(orginal_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    height, width = orginal_image.shape[:2]\n",
    "    image_center = (width // 2, height // 2)\n",
    "\n",
    "    def calculate_distance(pt1, pt2):\n",
    "        return np.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "    max_distance_from_center = min(width, height) * 0.25\n",
    "\n",
    "    center_contours = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            centroid = (cx, cy)\n",
    "\n",
    "            distance_to_center = calculate_distance(centroid, image_center)\n",
    "\n",
    "            if distance_to_center <= max_distance_from_center:\n",
    "                center_contours.append(contour)\n",
    "\n",
    "    if center_contours:\n",
    "        largest_contour = max(center_contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        larges_center_contour_area=cv2.contourArea(largest_contour)\n",
    "        return larges_center_contour_area,x,y,w,h\n",
    "\n",
    "    else:\n",
    "        return -1,0,0,0,0\n",
    "\n",
    "def _iou(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    prob_mask = outputs.sigmoid()\n",
    "    pred_mask = (prob_mask > 0.5).float()\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), labels.long(), mode=\"binary\")\n",
    "    return smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "def _accuracy(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    prob_mask = outputs.sigmoid()\n",
    "    pred_mask = (prob_mask > 0.5).float()\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), labels.long(), mode=\"binary\")\n",
    "    return smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "\n",
    "class CustomModelBase(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, accuracy_function=_accuracy, iou_function=_iou):\n",
    "        super(CustomModelBase, self).__init__()\n",
    "        # self.class_weights = class_weights\n",
    "        # self.loss_function = loss_function\n",
    "        self.accuracy_function = accuracy_function\n",
    "        self.iou_function = iou_function\n",
    "\n",
    "class CreateModel(CustomModelBase):\n",
    "    def __init__(self, model):\n",
    "        super(CreateModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def runInference(image , threshold = 0.5):\n",
    "    h,w = image.height, image.width\n",
    "    image = resize(image)\n",
    "\n",
    "    image1 = TF.to_tensor(image)\n",
    "\n",
    "    tensor_input = TF.normalize(image1, mean=mean, std=std)\n",
    "\n",
    "    tensor_input = tensor_input.to(device).float()\n",
    "\n",
    "    output = model.forward(tensor_input[None])[0].squeeze()\n",
    "\n",
    "    prob_mask = output.sigmoid().cpu().numpy()\n",
    "    output_mask = (prob_mask > threshold)\n",
    "    output_mask = (output_mask * 255).astype(np.uint8)\n",
    "    output_mask = cv2.resize(output_mask, (w,h))\n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('', map_location=torch.device('cuda'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = ''\n",
    "output_path = ''\n",
    "resize = transforms.Resize(size=(512, 512))\n",
    "folders = os.listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "total_dice = 0\n",
    "with torch.no_grad():\n",
    "    for folder in folders:\n",
    "        all_reps = os.listdir(os.path.join(input_path, folder))\n",
    "        print(os.path.join(input_path, folder))\n",
    "        for rep in all_reps:\n",
    "            print(rep)\n",
    "            input_images = os.path.join(input_path, folder, rep)\n",
    "            all_files = glob.glob(input_images + '/*')\n",
    "            dest_path = os.path.join(output_path, folder, rep)\n",
    "            os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "            for imagepth in tqdm(all_files):\n",
    "\n",
    "                image_id = os.path.basename(imagepth)\n",
    "                image = Image.open(imagepth)\n",
    "                opencv_image = np.array(image)\n",
    "                org_h, org_w = opencv_image.shape[:2]\n",
    "                input_image_width = image.width\n",
    "                input_image_height = image.height\n",
    "\n",
    "                output_mask = runInference(image.copy())\n",
    "                area_of_center_leaf,x,y,w,h = get_area_of_leaf(output_mask)\n",
    "\n",
    "                if area_of_center_leaf < (input_image_width * input_image_height * 0.005):\n",
    "                    x_diff, y_diff = 120, 120\n",
    "\n",
    "                    cropped_img = opencv_image[y_diff: -y_diff, x_diff: -x_diff]\n",
    "\n",
    "                    blank_img = np.zeros_like(opencv_image)\n",
    "                    blank_img = cv2.cvtColor(blank_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    output_mask = runInference(Image.fromarray(cropped_img), threshold=0.5)\n",
    "\n",
    "\n",
    "                    blank_img[y_diff: -y_diff, x_diff: -x_diff] = output_mask\n",
    "                    output_mask = blank_img\n",
    "\n",
    "\n",
    "                remove_noise_mask = new_remove_noise(output_mask)\n",
    "\n",
    "                remove_noise_mask = cv2.resize(remove_noise_mask, (org_w,org_h))\n",
    "\n",
    "\n",
    "                mask_dir_path = os.path.join(dest_path, \"masks\")\n",
    "                os.makedirs(mask_dir_path, exist_ok=True)\n",
    "                remove_noise_mask_3 = cv2.cvtColor(remove_noise_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                cv2.imwrite(f\"{mask_dir_path}/{image_id[:-4]}_mask.png\", remove_noise_mask_3)\n",
    "                seg_image = np.where(remove_noise_mask_3 == 0, 0, image)\n",
    "                seg_image = cv2.cvtColor(seg_image.astype('uint8'), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                dir_path = os.path.join(dest_path, \"segmented_images\")\n",
    "                os.makedirs(dir_path, exist_ok=True)\n",
    "                cv2.imwrite(f\"{dir_path}/{image_id[:-4]}_seg.png\", seg_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
