{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd5abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import glob\n",
    "from os.path import join, isfile, isdir, basename, splitext, exists\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "import cv2\n",
    "import shutil\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from pathlib import PureWindowsPath\n",
    "from skimage.measure import regionprops, regionprops_table, find_contours, label\n",
    "from skimage.morphology import convex_hull_image\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc02edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files from a given path\n",
    "def get_all_files(path, only_filenames, sorted_list):\n",
    "    file_list = [x for x in glob.glob(join(path, '*.*')) if isfile(x)]\n",
    "    if only_filenames:\n",
    "        file_list = [x.split('\\\\')[-1] for x in file_list]\n",
    "    if sorted_list:\n",
    "        return sorted(file_list)\n",
    "    return file_list\n",
    "\n",
    "# List all folders from a given path\n",
    "def get_all_folders(path, only_foldernames, sorted_list):\n",
    "    file_list = [x for x in glob.glob(join(path, '*')) if isdir(x)]\n",
    "    if only_foldernames:\n",
    "        file_list = [x.split('\\\\')[-1] for x in file_list]\n",
    "    if sorted_list:\n",
    "        return sorted(file_list)\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd4e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mask from file\n",
    "def read_mask(mask_path):\n",
    "    init_mask = cv2.imread(mask_path)\n",
    "    if len(init_mask.shape) == 2:\n",
    "        return init_mask\n",
    "    return np.max(init_mask, axis=2)\n",
    "\n",
    "# Read leaf mask from file\n",
    "def read_leaf_mask(base_leaves_path, leaf_id, filename, leaf_seq_in_path=True):\n",
    "    if leaf_seq_in_path:\n",
    "        mask_path = join(base_leaves_path,\n",
    "                         'Leaf_{:03d}'.format(leaf_id),\n",
    "                         'leaf seq',\n",
    "                         'hidden leaf mask seq')\n",
    "    else:\n",
    "        mask_path = join(base_leaves_path,\n",
    "                         'Leaf_{:03d}'.format(leaf_id),\n",
    "                         'hidden leaf mask seq')\n",
    "    return read_mask(join(mask_path, filename))\n",
    "\n",
    "# Read stem mask from file\n",
    "def read_stem_mask(base_leaves_path, leaf_id, filename):\n",
    "    return read_mask(join(base_leaves_path,\n",
    "                          'Leaf_{:03d}'.format(leaf_id),\n",
    "                          'stem seq',\n",
    "                          'hidden stem mask seq',\n",
    "                          filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fed204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct filenames in a replicate\n",
    "def get_all_filenames_in_replicate(rep_path, leaf_seq_in_path=True):\n",
    "    all_filenames = []\n",
    "    leaves_per_filename = defaultdict(list)\n",
    "    for leaf_folder in get_all_folders(rep_path, only_foldernames=True, sorted_list=True):\n",
    "        if leaf_seq_in_path:\n",
    "            leaf_path = join(rep_path, leaf_folder, 'leaf seq', 'hidden leaf mask seq')\n",
    "        else:\n",
    "            leaf_path = join(rep_path, leaf_folder, 'hidden leaf mask seq')\n",
    "        curr_filenames = get_all_files(\n",
    "            leaf_path,\n",
    "            only_filenames=True,\n",
    "            sorted_list=False)\n",
    "        all_filenames.extend(curr_filenames)\n",
    "        for filename in curr_filenames:\n",
    "            leaves_per_filename[filename].append(leaf_folder)\n",
    "    return sorted(list(set(all_filenames))), leaves_per_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb7ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date and time from filename\n",
    "def extract_date_time_from_filename(filename):\n",
    "    dt_parts = [int(x) for i_x, x in enumerate(filename.split('_')) if i_x < 6]\n",
    "    return tuple(dt_parts[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d956c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract leaf contour\n",
    "def extract_leaf_contour(leaf_mask):\n",
    "    return find_contours(leaf_mask)[0]\n",
    "\n",
    "\n",
    "\n",
    "# Rotate the contour so that it starts at the base of the petiole\n",
    "# \"pt_towards_plant_center\" is a point towards the center of the plant, not the center of the leaf.\n",
    "def make_contour_start_at_petiole_base(leaf_contour, pt_towards_plant_center):\n",
    "    petiole_start_idx = np.argmin(cdist(pt_towards_plant_center, leaf_contour))\n",
    "    return np.roll(leaf_contour, -petiole_start_idx, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the length of each contour segment and return the cumulative contour length \n",
    "def cumulative_contour_length(contour):\n",
    "    contour_length = np.zeros((len(contour),), dtype=float)\n",
    "    contour_length[1:] = np.cumsum(np.sqrt(np.sum(np.square(contour[:-1, :] - contour[1:, :]),\n",
    "                                                  axis=1)))\n",
    "    return contour_length\n",
    "\n",
    "\n",
    "\n",
    "# Take the length of a contour, map it to [0...1] and pick a point on the contour at the given ratio\n",
    "def point_at_contour_ratio(contour, length_ratio, desired_ratio):\n",
    "    # Pick the closest contour point after the given ratio\n",
    "    idx = np.where(length_ratio >= desired_ratio)[0][0]\n",
    "    if length_ratio[idx] == desired_ratio:\n",
    "        # There is a precise contour point which is located at the desired ratio\n",
    "        return contour[idx, :]\n",
    "    \n",
    "    # Find a point in between two contour points that lies at the desired point\n",
    "    rest_ratio = desired_ratio - length_ratio[idx]\n",
    "    rest_ratio_weigth = rest_ratio / (length_ratio[idx] - length_ratio[idx - 1])\n",
    "    return (1 - rest_ratio_weigth) * contour[idx - 1, :] + rest_ratio_weigth * contour[idx, :]\n",
    "\n",
    "\n",
    "\n",
    "# Extract leaf vein based on the leaf contour.\n",
    "# \"top_idx\" represents the contour index of the top of the leaf\n",
    "def extract_leaf_vein(leaf_contour, top_idx):\n",
    "    # Compute left and right contours and the cumulative distances along each one,\n",
    "    # as well as ratio values of each point along the contour it belongs to.\n",
    "    left_contour = leaf_contour[:(1 + top_idx), :]\n",
    "    right_contour = np.roll(leaf_contour, -1, axis=0)[(top_idx - 1):, :][::-1, :]  # Reverse order in order to start from petiole\n",
    "    left_cum_length = cumulative_contour_length(left_contour)\n",
    "    right_cum_length = cumulative_contour_length(right_contour)\n",
    "    left_ratio = left_cum_length/left_cum_length[-1]\n",
    "    right_ratio = right_cum_length/right_cum_length[-1] #  [x/right_cum_length[-1] for x in right_cum_length]\n",
    "\n",
    "    # Pick the number of desired points along the leaf vein\n",
    "    #     n_pts = max(left_contour.shape[0], right_contour.shape[0])\n",
    "    n_pts = 20\n",
    "    \n",
    "    # Create leaf vein points as halfway points between points with the same ratio value on left and right contours\n",
    "    leaf_vein = np.zeros((n_pts, 2), dtype=float)\n",
    "    for i_pt in range(n_pts):\n",
    "        curr_ratio = i_pt / (n_pts - 1)\n",
    "        \n",
    "        # Leaf vein points are calculated as halfway through the distance between\n",
    "        # the points on left/right contours located at the same relative ratio\n",
    "        leaf_vein[i_pt, :] = (point_at_contour_ratio(left_contour, left_ratio, curr_ratio) \n",
    "                              + point_at_contour_ratio(right_contour, right_ratio, curr_ratio)) / 2.0\n",
    "    return leaf_vein\n",
    "\n",
    "\n",
    "\n",
    "# Calculate a moving average along a given data vector \"a\"\n",
    "# If radius is 2 the moving window has 1+2*radius size (1 for the middle element) \n",
    "def moving_average(a, radius):\n",
    "    # w_sz is the window size\n",
    "    w_sz = 1 + 2 * radius\n",
    "    avg_res = np.zeros_like(a, dtype=float)\n",
    "    \n",
    "    # Compute cumulative sum\n",
    "    a_cumsum = np.zeros((1 + a.size), dtype=float)  # One artificial zero is added at the beginning\n",
    "    a_cumsum[1:] = np.cumsum(a, dtype=float)\n",
    "    \n",
    "    # Most average values can be computed as differences between the cumulative sum values at locations\n",
    "    # found at w_sz distance from each other\n",
    "    avg_res[radius:(a.size - radius)] = (a_cumsum[w_sz:] - a_cumsum[:(a.size - w_sz + 1)]) / w_sz\n",
    "    \n",
    "    # Some values at the beginning and at the end need special attention\n",
    "    avg_res[0] = a[0]\n",
    "    avg_res[-1] = a[-1]\n",
    "    for idx in range(1, radius):\n",
    "        curr_w_sz = 1 + 2 * idx\n",
    "        avg_res[idx] = a_cumsum[curr_w_sz] / curr_w_sz\n",
    "        avg_res[a.size - idx - 1] = (a_cumsum[-1] - a_cumsum[a.size - curr_w_sz]) / curr_w_sz        \n",
    "    return avg_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4719ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intersection between an infinite line and a limited segment\n",
    "# Points a and b define the line, points c and d define the segment\n",
    "def line_segment_intersection(a, b, c, d):\n",
    "    # The denominator comes from a special mathematical formula\n",
    "    denominator = (a[0] - b[0]) * (c[1] - d[1]) - (a[1] - b[1]) * (c[0] - d[0])\n",
    "    if denominator == 0:\n",
    "        # The segment is parallel with the line. Return error.\n",
    "        return False, None\n",
    "    \n",
    "    # Parametric values of the intersection:\n",
    "    # t is between 0 and 1 if the intersection falls between the two points (a and b) of the line\n",
    "    # u is between 0 and 1 if the intersection falls between the two points (c and d) of the segment\n",
    "    t = ((a[0] - c[0]) * (c[1] - d[1]) - (a[1] - c[1]) * (c[0] - d[0])) / denominator\n",
    "    u = ((a[0] - c[0]) * (a[1] - b[1]) - (a[1] - c[1]) * (a[0] - b[0])) / denominator\n",
    "\n",
    "    # Check if lines actually intersect\n",
    "    if (0 <= u <= 1):\n",
    "        # Intersection falls inside the segment\n",
    "        return True, np.array([a[0] + t * (b[0] - a[0]), a[1] + t * (b[1] - a[1])], dtype=float).reshape((1, 2))\n",
    "    \n",
    "    # Intersection falls outside the segment\n",
    "    return False, None\n",
    "\n",
    "\n",
    "\n",
    "# Compute the intersection between an infinite line (defined by two points) and a contour (a list of at least two points)\n",
    "def line_contour_intersection(line, contour):\n",
    "    intersection_pt = None\n",
    "    min_intersection_dist = np.inf\n",
    "    \n",
    "    # Compute intersection of the line with each segment of the contour\n",
    "    for seg_idx in range(contour.shape[0] - 1):\n",
    "        intersection_found, curr_intersection_pt = line_segment_intersection(\n",
    "            line[0, :], line[1, :], \n",
    "            contour[seg_idx, :], contour[seg_idx + 1, :])\n",
    "\n",
    "        if intersection_found:\n",
    "            curr_dist = cdist(line[:1, :], curr_intersection_pt)\n",
    "            if curr_dist < min_intersection_dist:\n",
    "                # Keep only the closest intersection\n",
    "                intersection_pt = curr_intersection_pt\n",
    "                min_intersection_dist = curr_dist\n",
    "    return intersection_pt\n",
    "\n",
    "\n",
    "\n",
    "# Compute the distance from a point to an infinite line by projecting it orthogonally to the line\n",
    "def distance_from_pt_to_line(pt, line):\n",
    "    return np.linalg.norm(np.cross(-np.diff(line, axis=0), line[0, :] - pt)) / np.linalg.norm(-np.diff(line, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b5ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find plant centers based on stem overlaps at the center\n",
    "def find_plant_centers___per_rep(stem_rep_path):  # , base_combi_vis_path):\n",
    "    stem_sums = dict()\n",
    "    all_leaf_foldernames = get_all_folders(stem_rep_path, only_foldernames=True, sorted_list=True)\n",
    "    for leaf_foldername in all_leaf_foldernames:\n",
    "        leaf_id = int(leaf_foldername[-3:])\n",
    "        stem_masks_path = join(stem_rep_path, leaf_foldername, 'stem seq', 'hidden stem mask seq')\n",
    "        all_mask_paths = get_all_files(stem_masks_path, only_filenames=False, sorted_list=True)\n",
    "        for mask_path in all_mask_paths:\n",
    "            curr_mask_filename = mask_path.split('\\\\')[-1]\n",
    "            curr_mask = read_mask(join(stem_rep_path,\n",
    "                                       'Leaf_{:03d}'.format(leaf_id),\n",
    "                                       'stem seq',\n",
    "                                       'hidden stem mask seq',\n",
    "                                       curr_mask_filename)).astype(float) / 255.0\n",
    "            if curr_mask_filename not in stem_sums:\n",
    "                stem_sums[curr_mask_filename] = curr_mask\n",
    "            else:\n",
    "                if np.any(np.array(stem_sums[curr_mask_filename].shape) < np.array(curr_mask.shape)):\n",
    "                    enlarged_img = np.zeros((max(stem_sums[curr_mask_filename].shape[0], curr_mask.shape[0]),\n",
    "                                             max(stem_sums[curr_mask_filename].shape[1], curr_mask.shape[1])),\n",
    "                                            dtype=stem_sums[curr_mask_filename].dtype)\n",
    "                    enlarged_img[:stem_sums[curr_mask_filename].shape[0],\n",
    "                                 :stem_sums[curr_mask_filename].shape[1]] = stem_sums[curr_mask_filename]\n",
    "                    stem_sums[curr_mask_filename] = enlarged_img\n",
    "                stem_sums[curr_mask_filename][:curr_mask.shape[0], :curr_mask.shape[1]] += curr_mask\n",
    "                    \n",
    "    plant_centers = dict()\n",
    "    for filename, stem_sum in stem_sums.items():\n",
    "        plant_centers[filename] = np.unravel_index(np.argmax(stem_sum), stem_sum.shape)  # (Y, X) order\n",
    "    \n",
    "    return plant_centers, stem_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc28e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute isotropies at replicate level\n",
    "def compute_rep_isotropy(leaf_base_path, dataset, acc, rep, leaf_seq_in_path,\n",
    "                         leaf_mask_profiles, plant_centers, parallelize):\n",
    "    isotropies = []\n",
    "    leaf_angles_per_date = defaultdict(list)\n",
    "    for profile in leaf_mask_profiles:\n",
    "        time_parts = profile[1].split(':')\n",
    "        leaf_angles_per_date[profile[0].year, profile[0].month, profile[0].day,\n",
    "                             int(time_parts[0]), int(time_parts[1])].append((profile[4], profile[15]))  # leaf, angle\n",
    "    all_filenames, leaves_per_filename = get_all_filenames_in_replicate(join(leaf_base_path, dataset, acc, rep),\n",
    "                                                                        leaf_seq_in_path)\n",
    "    for filename in all_filenames:\n",
    "        curr_special_convex_hull = None\n",
    "        curr_plant_center = plant_centers[filename]\n",
    "        mask_cache = dict()\n",
    "        year, month, day, hour, minute = extract_date_time_from_filename(filename)\n",
    "        curr_leaf_angles = sorted(leaf_angles_per_date[year, month, day, hour, minute],\n",
    "                                  key=lambda x: x[1])\n",
    "        n_items = len(curr_leaf_angles)\n",
    "        for i_leaf in range(n_items):\n",
    "            leaf_id, leaf_angle = curr_leaf_angles[i_leaf]\n",
    "            if leaf_seq_in_path:\n",
    "                leaf_path = join(leaf_base_path, dataset, acc, rep, 'Leaf_{:03d}'.format(leaf_id),\n",
    "                                 'leaf seq', 'hidden leaf mask seq')\n",
    "            else:\n",
    "                leaf_path = join(leaf_base_path, dataset, acc, rep, 'Leaf_{:03d}'.format(leaf_id),\n",
    "                                 'hidden leaf mask seq')\n",
    "            if leaf_id not in mask_cache.keys():\n",
    "                mask_cache[leaf_id] = (read_mask(\n",
    "                    join(leaf_path, filename)) > 0).astype(np.uint8)\n",
    "            next_leaf_id = (i_leaf + 1) % n_items\n",
    "            if next_leaf_id not in mask_cache.keys():\n",
    "                mask_cache[next_leaf_id] = (read_mask(\n",
    "                    join(leaf_path, filename)) > 0).astype(np.uint8)\n",
    "            if np.any(np.array(mask_cache[leaf_id].shape) != np.array(mask_cache[next_leaf_id].shape)):\n",
    "                resized_next_mask = np.zeros_like(np.array(mask_cache[leaf_id]))\n",
    "                copy_ranges = (min(mask_cache[leaf_id].shape[0], mask_cache[next_leaf_id].shape[0]),\n",
    "                               min(mask_cache[leaf_id].shape[1], mask_cache[next_leaf_id].shape[1]))\n",
    "                resized_next_mask[:copy_ranges[0], :copy_ranges[1]] = \\\n",
    "                    mask_cache[next_leaf_id][:copy_ranges[0], :copy_ranges[1]]\n",
    "                combi_convex_hull = np.maximum(mask_cache[leaf_id], resized_next_mask)\n",
    "            else:\n",
    "                combi_convex_hull = np.maximum(mask_cache[leaf_id], mask_cache[next_leaf_id])\n",
    "            combi_convex_hull[curr_plant_center[1], curr_plant_center[0]] = 1\n",
    "            combi_convex_hull = convex_hull_image(combi_convex_hull)\n",
    "            if curr_special_convex_hull is None:\n",
    "                curr_special_convex_hull = combi_convex_hull\n",
    "            else:\n",
    "                if np.any(np.array(curr_special_convex_hull.shape) != np.array(combi_convex_hull.shape)):\n",
    "                    resized_convex_hull = np.zeros_like(np.array(curr_special_convex_hull))\n",
    "                    copy_ranges = (min(curr_special_convex_hull.shape[0], combi_convex_hull.shape[0]),\n",
    "                                   min(curr_special_convex_hull.shape[1], combi_convex_hull.shape[1]))\n",
    "                    resized_convex_hull[:copy_ranges[0], :copy_ranges[1]] = \\\n",
    "                        combi_convex_hull[:copy_ranges[0], :copy_ranges[1]]\n",
    "                    combi_convex_hull = np.maximum(curr_special_convex_hull, resized_convex_hull)\n",
    "                else:\n",
    "                    curr_special_convex_hull = np.maximum(curr_special_convex_hull, combi_convex_hull)\n",
    "        if curr_special_convex_hull is None:\n",
    "            print('ERROR: curr_special_convex_hull is None!')\n",
    "        else:\n",
    "            curr_special_convex_hull = binary_fill_holes(curr_special_convex_hull).astype(int)\n",
    "            pix_mask_props = regionprops(curr_special_convex_hull)[0]\n",
    "            curr_date = date(year, month, day)\n",
    "            curr_time = '{:02d}:{:02d}'.format(hour, minute)\n",
    "            isotropies.append((curr_date, curr_time, dataset, acc, int(rep[-2:]),\n",
    "                               np.round(4 * np.pi * pix_mask_props['area'] / (pix_mask_props['perimeter']\n",
    "                                                                              * pix_mask_props['perimeter']),\n",
    "                                        3)))\n",
    "    return isotropies\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfd66b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute length and width of leaf lobe\n",
    "def compute_length_and_width_of_leaf_lobe(leaf_mask_contour_XY, plant_center_XY):\n",
    "    leaf_dists = compute_contour_distances(plant_center_XY, leaf_mask_contour_XY)\n",
    "    idx_bottom_pt = np.argmin(leaf_dists)\n",
    "    rolled_leaf_contour_XY = np.roll(leaf_mask_contour_XY, -idx_bottom_pt, axis = 0)\n",
    "\n",
    "    idx_top_pt = (np.argmax(leaf_dists) - idx_bottom_pt) % leaf_dists.shape[0]\n",
    "    leaf_vein = extract_leaf_vein(rolled_leaf_contour_XY, idx_top_pt)\n",
    "\n",
    "    inters_pts_left = []\n",
    "    inters_pts_right = []\n",
    "    dists = [0.0]\n",
    "    # First and last points on the leaf vein do not count\n",
    "    for seg_idx_vein in range(1, leaf_vein.shape[0] - 1):\n",
    "        curr_angle = np.arctan2(leaf_vein[seg_idx_vein, 1] - leaf_vein[(seg_idx_vein - 1), 1], \n",
    "                                leaf_vein[seg_idx_vein, 0] - leaf_vein[(seg_idx_vein - 1), 0])\n",
    "        ortho_angle = np.mod(np.pi/2.0 + curr_angle, np.pi)\n",
    "        line = leaf_vein[(seg_idx_vein - 1):(seg_idx_vein + 1), :][::-1, :].copy()\n",
    "        line[1, 0] = line[0, 0] + 10 * np.cos(ortho_angle)\n",
    "        line[1, 1] = line[0, 1] + 10 * np.sin(ortho_angle)\n",
    "        curr_inters_pt_left = line_contour_intersection(line, rolled_leaf_contour_XY[:(1+idx_top_pt), :])\n",
    "        curr_inters_pt_right = line_contour_intersection(line, rolled_leaf_contour_XY[idx_top_pt:, :])\n",
    "        if curr_inters_pt_left is not None and curr_inters_pt_right is not None:\n",
    "            inters_pts_left.append(curr_inters_pt_left)\n",
    "            inters_pts_right.append(curr_inters_pt_right)\n",
    "            dists.append(cdist(curr_inters_pt_left, curr_inters_pt_right)[0, 0])\n",
    "    dists.append(0.0)\n",
    "    \n",
    "    cum_lengths = cumulative_contour_length(leaf_vein)\n",
    "    \n",
    "    return cum_lengths[-1], max(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c729345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ellipse based on 2nd central moment of a mask\n",
    "def get_ellipse_based_on_2nd_central_moment(mask):\n",
    "    mask_points = np.transpose(np.nonzero(mask))\n",
    "    if mask_points.size == 0:\n",
    "        return [0.0,  # Center.X\n",
    "                0.0,  # Center.Y\n",
    "                -1.0,  # Major radius\n",
    "                -1.0,  # Minor radius\n",
    "                -1.0,  # Angle major radius\n",
    "                -1000.0]  # Area\n",
    "    if mask_points.size == 1:\n",
    "        return [mask_points[0, 1] + 0.5,  # Center.X\n",
    "                mask_points[0, 0] + 0.5,  # Center.Y\n",
    "                0.5,  # Major radius\n",
    "                0.5,  # Minor radius\n",
    "                0.0,  # Angle major radius\n",
    "                1.0]  # Area\n",
    "\n",
    "    ellipse_data = []\n",
    "    \n",
    "    M00 = float(mask_points.shape[0])\n",
    "    M01 = 0.0\n",
    "    M10 = 0.0\n",
    "    M02 = 0.0\n",
    "    M20 = 0.0\n",
    "    M11 = 0.0\n",
    "    for i_pt in range(mask_points.shape[0]):\n",
    "        M01 += mask_points[i_pt, 0]\n",
    "        M10 += mask_points[i_pt, 1]\n",
    "        M02 += mask_points[i_pt, 0] * mask_points[i_pt, 0]\n",
    "        M20 += mask_points[i_pt, 1] * mask_points[i_pt, 1]\n",
    "        M11 += mask_points[i_pt, 1] * mask_points[i_pt, 0]\n",
    "    ellipse_data.append(M10 / M00)  # Center.X\n",
    "    ellipse_data.append(M01 / M00)  # Center.Y\n",
    "    \n",
    "    mu_20 = M20 / M00 - ellipse_data[0] * ellipse_data[0]\n",
    "    mu_02 = M02 / M00 - ellipse_data[1] * ellipse_data[1]\n",
    "    mu_11 = M11 / M00 - ellipse_data[0] * ellipse_data[1]\n",
    "    \n",
    "    delta = np.sqrt(4 * mu_11 * mu_11 + (mu_20 - mu_02) * (mu_20 - mu_02))\n",
    "    lambda_1 = ((mu_20 + mu_02) + delta) / 2.0\n",
    "    lambda_2 = ((mu_20 + mu_02) - delta) / 2.0\n",
    "    \n",
    "    ellipse_data.append(np.sqrt(2.0 * np.abs(lambda_1)))  # Major radius\n",
    "    ellipse_data.append(np.sqrt(2.0 * np.abs(lambda_2)))  # Minor radius\n",
    "    \n",
    "    angle = 0.0\n",
    "    if mu_20 != mu_02:\n",
    "        angle = 0.5 * np.arctan([(2.0 * mu_11) / (np.sign(mu_20 - mu_02) * (mu_20 - mu_02)),\n",
    "                                 1]) * 180.0 / np.pi\n",
    "    angle = np.mod(angle + 90.0, 180.0)\n",
    "    ellipse_data.append(angle)  # Angle major radius\n",
    "    \n",
    "    ellipse_data.append(M00)  # Area\n",
    "    \n",
    "    return ellipse_data\n",
    "    \n",
    "\n",
    "# Compute distances from center to contour pixels\n",
    "def compute_contour_distances(center, contour):\n",
    "    return cdist(center, contour).flatten()\n",
    "\n",
    "\n",
    "# Compute leaf mask profile (i.e. list of traits)\n",
    "def compute_leaf_mask_profile(leaf_mask, leaf_column_list, plant_center, pot_area_calibrated, calibration_factor = 1):\n",
    "    leaf_mask_profile = dict()\n",
    "    pix_mask_props = regionprops(leaf_mask)[0]\n",
    "    leaf_mask_profile['l_area (mm^2)'] = pix_mask_props['area'] * calibration_factor * calibration_factor\n",
    "    l_convex_hull_area_calibrated = pix_mask_props['area_convex'] * calibration_factor * calibration_factor\n",
    "    leaf_mask_profile['l_perimeter (mm)'] = pix_mask_props['perimeter'] * calibration_factor\n",
    "    leaf_mask_profile['l_eccentricity'] = pix_mask_props['eccentricity']\n",
    "    \n",
    "    leaf_mask_profile['l_roundness'] = \\\n",
    "        4.0 * np.pi * leaf_mask_profile['l_area (mm^2)'] / (leaf_mask_profile['l_perimeter (mm)']\n",
    "                                                            * leaf_mask_profile['l_perimeter (mm)'])\n",
    "    \n",
    "    contour_results = cv2.findContours(leaf_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    leaf_mask_contour_XY = np.squeeze(contour_results[0])\n",
    "    pix_bounding_circle_center, pix_bounding_circle_radius = cv2.minEnclosingCircle(leaf_mask_contour_XY)\n",
    "    leaf_mask_profile['l_circumference (mm)'] = 2.0 * np.pi * pix_bounding_circle_radius * calibration_factor\n",
    "    \n",
    "    leaf_mask_profile['l_compactness'] = leaf_mask_profile['l_area (mm^2)'] / l_convex_hull_area_calibrated\n",
    "\n",
    "    leaf_mask_profile['l_surface_coverage'] = \\\n",
    "        leaf_mask_profile['l_area (mm^2)'] / (np.pi * pix_bounding_circle_radius * pix_bounding_circle_radius\n",
    "                                              * calibration_factor * calibration_factor)\n",
    "\n",
    "    pix_rot_bbox_center, (pix_rot_bbox_width, pix_rot_bbox_height), rot_bbox_angle = cv2.minAreaRect(leaf_mask_contour_XY)\n",
    "    l_bounding_box_area_calibrated = pix_rot_bbox_width * pix_rot_bbox_height * calibration_factor * calibration_factor\n",
    "    \n",
    "    leaf_mask_profile['l_extent'] = leaf_mask_profile['l_area (mm^2)'] / l_bounding_box_area_calibrated\n",
    "    \n",
    "    ellipse_2nd_central_moment = get_ellipse_based_on_2nd_central_moment(leaf_mask)\n",
    "    leaf_mask_profile['l_RMA'] = 0.0\n",
    "    if ellipse_2nd_central_moment[2] > 0:  # Major radius\n",
    "        leaf_mask_profile['l_RMA'] = \\\n",
    "            2 * np.sqrt((ellipse_2nd_central_moment[2] / 2.0) ** 2\n",
    "                        - (ellipse_2nd_central_moment[3] / 2.0) ** 2) / ellipse_2nd_central_moment[2]\n",
    "\n",
    "    leaf_dists = compute_contour_distances(plant_center[:, ::-1], leaf_mask_contour_XY)\n",
    "    idx_bottom_pt = np.argmin(leaf_dists)\n",
    "    leaf_bottom_pt = np.reshape(leaf_mask_contour_XY[idx_bottom_pt, ::-1], (1, 2))\n",
    "    leaf_top_pt = np.reshape(leaf_mask_contour_XY[np.argmax(leaf_dists), ::-1], (1, 2))\n",
    "    rolled_leaf_contour_XY = np.roll(leaf_mask_contour_XY, -idx_bottom_pt, axis = 0)\n",
    "    rolled_idx_top_pt = (np.argmax(leaf_dists) - idx_bottom_pt) % leaf_mask_contour_XY.shape[0]\n",
    "    \n",
    "    leaf_mask_profile['l_angle (deg)'] = np.arctan2(leaf_bottom_pt[0, 0] - leaf_top_pt[0, 0],\n",
    "                                                    leaf_top_pt[0, 1] - leaf_bottom_pt[0, 1]) * 180.0 / np.pi\n",
    "    \n",
    "\n",
    "    pix_lamina_length, pix_lamina_width = compute_length_and_width_of_leaf_lobe(leaf_mask_contour_XY[::-1, :],\n",
    "                                                                                plant_center[:, ::-1])\n",
    "    leaf_mask_profile['l_lamina_length (mm)'] = pix_lamina_length * calibration_factor\n",
    "    leaf_mask_profile['l_width (mm)'] = pix_lamina_width * calibration_factor\n",
    "    leaf_mask_profile['l_petiole_length (mm)'] = \\\n",
    "        compute_contour_distances(plant_center, leaf_bottom_pt)[0] * calibration_factor\n",
    "    leaf_mask_profile['l_length (mm)'] = \\\n",
    "        leaf_mask_profile['l_petiole_length (mm)'] + leaf_mask_profile['l_lamina_length (mm)']\n",
    "    leaf_mask_profile['SOL'] = \\\n",
    "        leaf_mask_profile['l_lamina_length (mm)'] * leaf_mask_profile['l_lamina_length (mm)'] \\\n",
    "        / leaf_mask_profile['l_area (mm^2)']\n",
    "\n",
    "    leaf_mask_profile['l_LAI'] = leaf_mask_profile['l_area (mm^2)'] / pot_area_calibrated\n",
    "    \n",
    "    leaf_key_list = leaf_column_list + ['l_LAI']\n",
    "    return [np.round(leaf_mask_profile[k], 3) for k in leaf_key_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4dee505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute leaf traits, per leaf\n",
    "def compute_leaf_traits___per_leaf(leaf_base_path, dataset, acc, rep, leaf, leaf_seq_in_path,\n",
    "                                   leaf_column_list, plant_centers, pot_area_calibrated, calibration_factor):\n",
    "    leaf_mask_profiles = []\n",
    "    leaf_masks_per_datetime = defaultdict(list)\n",
    "    if leaf_seq_in_path:\n",
    "        leaf_path = join(leaf_base_path, dataset, acc, rep, leaf, 'leaf seq', 'hidden leaf mask seq')\n",
    "    else:\n",
    "        leaf_path = join(leaf_base_path, dataset, acc, rep, leaf, 'hidden leaf mask seq')\n",
    "    for i_leaf, leaf_instance in enumerate(get_all_files(leaf_path,\n",
    "                                                         only_filenames=True,\n",
    "                                                         sorted_list=True)):\n",
    "        leaf_mask = (read_mask(join(leaf_path, leaf_instance)) > 0).astype(np.uint8)\n",
    "        year, month, day, hour, minute = extract_date_time_from_filename(leaf_instance)\n",
    "        curr_date = date(year, month, day)\n",
    "        curr_time = '{:02d}:{:02d}'.format(hour, minute)\n",
    "        leaf_mask_profiles.append(\n",
    "            [curr_date, curr_time, acc, int(rep[-2:]), int(leaf[-3:])] + compute_leaf_mask_profile(\n",
    "                leaf_mask, leaf_column_list,\n",
    "                np.array(plant_centers[leaf_instance], ndmin=2), pot_area_calibrated, calibration_factor))\n",
    "        leaf_masks_per_datetime['{:04d}-{:02d}-{:02d}'.format(curr_date.year, curr_date.month, curr_date.day),\n",
    "                                curr_time].append((leaf, leaf_mask))\n",
    "    return leaf_mask_profiles, leaf_masks_per_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c970662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute leaf traits, per replicate\n",
    "def compute_leaf_traits___per_rep(leaf_base_path, dataset, acc, rep,\n",
    "                                  stem_base_path, leaf_seq_in_path,\n",
    "                                  leaf_column_list, pot_area_calibrated, calibration_factor, parallelize):\n",
    "    leaf_mask_profiles = []\n",
    "    leaf_LAI_per_datetime = defaultdict(list)\n",
    "    leaf_masks_per_datetime = defaultdict(list)\n",
    "    plant_density_masks_per_datetime = dict()\n",
    "    leaf_overlapping_percentage = dict()\n",
    "    rep_SOL_per_datetime = dict()\n",
    "    leaf_day_diff_per_rep = dict()\n",
    "    leaf_day_das_per_rep = dict()\n",
    "    rep_path = join(stem_base_path, dataset, acc, rep)\n",
    "    plant_centers, stem_sums_per_filename = find_plant_centers___per_rep(rep_path)\n",
    "    for leaf in get_all_folders(rep_path, only_foldernames=True, sorted_list=True):\n",
    "        if not parallelize:\n",
    "            print(f'\\t\\t\\t>>>>> Leaf: \"{leaf}\"')\n",
    "        leaf_instance_profiles, curr_leaf_masks_per_datetime = compute_leaf_traits___per_leaf(\n",
    "            leaf_base_path, dataset, acc, rep, leaf, leaf_seq_in_path,\n",
    "            leaf_column_list[:-1], plant_centers, pot_area_calibrated, calibration_factor)\n",
    "        for i_leaf, leaf_instance_profile in enumerate(leaf_instance_profiles):\n",
    "            curr_date = leaf_instance_profile[0]\n",
    "            curr_date_str = '{:04d}-{:02d}-{:02d}'.format(curr_date.year, curr_date.month, curr_date.day)\n",
    "            curr_time = leaf_instance_profile[1]\n",
    "            leaf_mask_profiles.append(leaf_instance_profile[:-1])  # Eliminate LAI from the common leaf traits\n",
    "            leaf_LAI_per_datetime[curr_date_str, curr_time].append(leaf_instance_profile[-1])  # LAI added here\n",
    "            if (curr_date_str, curr_time) not in leaf_masks_per_datetime:\n",
    "                for curr_leaf_id, curr_leaf_mask in curr_leaf_masks_per_datetime[curr_date_str, curr_time]:\n",
    "                    if curr_leaf_id == leaf:\n",
    "                        leaf_masks_per_datetime[curr_date_str, curr_time].append((curr_leaf_id, curr_leaf_mask))\n",
    "                        plant_density_masks_per_datetime[curr_date_str, curr_time] = curr_leaf_mask.copy()\n",
    "            else:\n",
    "                for curr_leaf_id, curr_leaf_mask in curr_leaf_masks_per_datetime[curr_date_str, curr_time]:\n",
    "                    if curr_leaf_id == leaf:\n",
    "                        if np.any(np.array(plant_density_masks_per_datetime[curr_date_str, curr_time].shape)\n",
    "                                  != np.array(curr_leaf_mask.shape)):\n",
    "                            resized_curr_leaf_mask = np.zeros_like(np.array(\n",
    "                                plant_density_masks_per_datetime[curr_date_str, curr_time]))\n",
    "                            copy_ranges = (min(resized_curr_leaf_mask.shape[0], curr_leaf_mask.shape[0]),\n",
    "                                           min(resized_curr_leaf_mask.shape[1], curr_leaf_mask.shape[1]))\n",
    "                            resized_curr_leaf_mask[:copy_ranges[0], :copy_ranges[1]] = \\\n",
    "                                curr_leaf_mask[:copy_ranges[0], :copy_ranges[1]]\n",
    "                            leaf_masks_per_datetime[curr_date_str, curr_time].append((curr_leaf_id, resized_curr_leaf_mask))\n",
    "                            plant_density_masks_per_datetime[curr_date_str, curr_time] += resized_curr_leaf_mask\n",
    "                        else:\n",
    "                            leaf_masks_per_datetime[curr_date_str, curr_time].append((curr_leaf_id, curr_leaf_mask))\n",
    "                            plant_density_masks_per_datetime[curr_date_str, curr_time] += curr_leaf_mask\n",
    "    # Compute overlapping percentages\n",
    "    for curr_date_str, curr_time in leaf_masks_per_datetime.keys():\n",
    "        curr_plant_density_mask = plant_density_masks_per_datetime[curr_date_str, curr_time]\n",
    "        for curr_leaf_id, curr_leaf_mask in leaf_masks_per_datetime[curr_date_str, curr_time]:\n",
    "            leafs_plant_density_mask = curr_plant_density_mask.copy()\n",
    "            leafs_plant_density_mask[np.logical_not(curr_leaf_mask.astype(bool))] = 0\n",
    "            leaf_overlapping_percentage[curr_date_str, curr_time, acc, rep, curr_leaf_id] = \\\n",
    "                np.round(100.0 * np.sum((leafs_plant_density_mask - curr_leaf_mask) > 0) / np.sum(curr_leaf_mask), 3)\n",
    "    # Add overlapping percentages to the rest of the data\n",
    "    for leaf_instance_profile in leaf_mask_profiles:\n",
    "        curr_date = leaf_instance_profile[0]\n",
    "        curr_date_str = '{:04d}-{:02d}-{:02d}'.format(curr_date.year, curr_date.month, curr_date.day)\n",
    "        curr_time = leaf_instance_profile[1]\n",
    "        leaf_instance_profile.append(\n",
    "            leaf_overlapping_percentage[curr_date_str, curr_time, acc, rep, 'Leaf_{:03d}'.format(leaf_instance_profile[4])])\n",
    "        \n",
    "    rep_isotropies = compute_rep_isotropy(leaf_base_path, dataset, acc, rep, leaf_seq_in_path,\n",
    "                                          leaf_mask_profiles, plant_centers, parallelize)\n",
    "    plant_traits = []\n",
    "    for curr_date, curr_time, curr_dataset, curr_acc, curr_rep, curr_isotropy in rep_isotropies:\n",
    "        curr_date_str = curr_date.strftime('%Y-%m-%d')\n",
    "        plant_traits.append([curr_date, curr_time, curr_acc, curr_rep,\n",
    "                             curr_isotropy,\n",
    "                             sum(leaf_LAI_per_datetime[curr_date_str, curr_time])])\n",
    "        ds2_start_screening_date = date(2022, 8, 2)\n",
    "        das_offset = 13 if curr_dataset == 'leaf_dataset1' else 11\n",
    "        if (curr_dataset, curr_acc, curr_rep) not in leaf_day_diff_per_rep.keys():\n",
    "            # We are at the first date from this combination, we can calculate the day difference\n",
    "            init_date = curr_date\n",
    "            day_delta = timedelta(0)\n",
    "            if curr_dataset == 'leaf_dataset2':\n",
    "                day_delta = timedelta(days=(curr_date - ds2_start_screening_date).days)\n",
    "        diff_to_first_day = timedelta(days=(curr_date - init_date).days)\n",
    "        leaf_day_diff_per_rep[curr_dataset, curr_acc, curr_rep] = day_delta\n",
    "        leaf_day_das_per_rep[curr_dataset, curr_acc, curr_rep, curr_date_str] = diff_to_first_day + timedelta(days=das_offset)\n",
    "    # Compute slenderness of leaves (SOL)\n",
    "    plant_SOL = dict()\n",
    "    for filename, curr_stem_sum in stem_sums_per_filename.items():\n",
    "        year, month, day, hour, minute = extract_date_time_from_filename(filename)\n",
    "        curr_date = date(year, month, day)\n",
    "        curr_date_str = '{:04d}-{:02d}-{:02d}'.format(year, month, day)\n",
    "        curr_time = '{:02d}:{:02d}'.format(hour, minute)\n",
    "        curr_plant_density_mask = plant_density_masks_per_datetime[curr_date_str, curr_time]\n",
    "        if np.any(np.array(curr_stem_sum.shape) != np.array(curr_plant_density_mask.shape)):\n",
    "            whole_img = np.zeros((max(curr_stem_sum.shape[0], curr_plant_density_mask.shape[0]),\n",
    "                                  max(curr_stem_sum.shape[1], curr_plant_density_mask.shape[1])),\n",
    "                                 dtype=curr_stem_sum.dtype)\n",
    "            whole_img[:curr_stem_sum.shape[0],\n",
    "                      :curr_stem_sum.shape[1]] = curr_stem_sum\n",
    "        else:\n",
    "            whole_img = curr_stem_sum.copy()\n",
    "        whole_img[:curr_plant_density_mask.shape[0],\n",
    "                  :curr_plant_density_mask.shape[1]] += curr_plant_density_mask\n",
    "        curr_area = np.sum(whole_img > 0) * calibration_factor * calibration_factor\n",
    "        curr_leaf_ids = set([int(x[0][-3:]) for x in leaf_masks_per_datetime[curr_date_str, curr_time]])\n",
    "        leaf_lengths = [x[15] for x in leaf_mask_profiles\n",
    "                        if x[0].strftime('%Y-%m-%d') == curr_date_str\n",
    "                        and x[1] == curr_time\n",
    "                        and x[2] == acc\n",
    "                        and x[3] == int(rep[4:])\n",
    "                        and x[4] in curr_leaf_ids]\n",
    "        sum_leaf_lengths = sum(leaf_lengths)\n",
    "        plant_SOL[curr_date_str, curr_time, acc, int(rep[4:])] = sum_leaf_lengths * sum_leaf_lengths / curr_area\n",
    "    for plant_trait in plant_traits:\n",
    "        plant_trait.append(plant_SOL[plant_trait[0].strftime('%Y-%m-%d'),\n",
    "                                     plant_trait[1],\n",
    "                                     plant_trait[2],\n",
    "                                     plant_trait[3]])\n",
    "    return leaf_mask_profiles, plant_traits, leaf_day_diff_per_rep, leaf_day_das_per_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1931aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shift_dates(init_profiles, curr_dataset, leaf_day_diff_per_rep, leaf_day_das_per_rep):\n",
    "    profiles = []\n",
    "    for profile in init_profiles:\n",
    "        curr_date = profile[0]\n",
    "        curr_date_str = curr_date.strftime('%Y-%m-%d')\n",
    "        curr_time = profile[1]\n",
    "        curr_acc = profile[2]\n",
    "        curr_rep = profile[3]\n",
    "        if curr_dataset == 'leaf_dataset1':\n",
    "            profiles.append(\n",
    "                [curr_date,\n",
    "                 curr_time,\n",
    "                 leaf_day_das_per_rep[curr_dataset, curr_acc, curr_rep, curr_date_str]]\n",
    "                + profile[2:])\n",
    "        else:\n",
    "            profiles.append(\n",
    "                [curr_date - leaf_day_diff_per_rep[curr_dataset, curr_acc, curr_rep],\n",
    "                 curr_time,\n",
    "                 leaf_day_das_per_rep[curr_dataset, curr_acc, curr_rep, curr_date_str]]\n",
    "                + profile[2:])\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896c3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to Excel file\n",
    "def save_to_excel(df_list, sheet_name_list, file_path):\n",
    "    n_items = len(df_list)\n",
    "    if n_items == 0:\n",
    "        print('>>>>>>> WARNING: NOTHING TO SAVE TO EXCEL.')\n",
    "        return\n",
    "    writer = pd.ExcelWriter(file_path, date_format='dd-mm-yyyy')\n",
    "    for i_df in range(n_items):\n",
    "        df = df_list[i_df]\n",
    "        sheet_name = sheet_name_list[i_df]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        for column in df:\n",
    "            column_length = int(1.35 * max(df[column].astype(str).map(len).max(), len(column)))\n",
    "            col_idx = df.columns.get_loc(column)\n",
    "            writer.sheets[sheet_name].set_column(col_idx, col_idx, column_length)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5951ee25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Complete datasets with cropped and visible leaves...\n",
      "> Dataset: \"leaf_dataset1\"\n",
      "\t>>> Accession: \"Ba4-1\"\n",
      "\t>>> Accession: \"Ba5-1\"\n",
      "\t>>> Accession: \"Bch-4\"\n",
      "\t>>> Accession: \"Col-0\"\n",
      "\t>>> Accession: \"Cvi-0\"\n",
      "\t>>> Accession: \"Ei-6\"\n",
      "\t>>> Accession: \"Go-0\"\n",
      "\t>>> Accession: \"Hs-0\"\n",
      "\t>>> Accession: \"Is-1\"\n",
      "\t>>> Accession: \"Kz-9\"\n",
      "\t>>> Accession: \"Ler-1\"\n",
      "\t>>> Accession: \"Lz-0\"\n",
      "\t>>> Accession: \"Or-0\"\n",
      "\t>>> Accession: \"Sav-0\"\n",
      "\t>>> Accession: \"TOU-I-17\"\n",
      "\t>>> Accession: \"TOU-J-3\"\n",
      "\t>>> Accession: \"Uk-1\"\n",
      "\t>>> Accession: \"Uk-4\"\n",
      "\t>>> Accession: \"Utrecht\"\n",
      "\t>>> Accession: \"Ws-2\"\n",
      "\t>>> Accession: \"Zdr-1\"\n",
      "> Dataset: \"leaf_dataset2\"\n",
      "\t>>> Accession: \"Col-0\"\n",
      "\t>>> Accession: \"Cvi-0\"\n",
      "\t>>> Accession: \"Is-1\"\n",
      "\t>>> Accession: \"Kz-9\"\n",
      "\t>>> Accession: \"Ler-1\"\n",
      "\t>>> Accession: \"TOU-I-17\"\n",
      "\t>>> Accession: \"Uk-1\"\n",
      "\t>>> Accession: \"Zdr-1\"\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "leaf_base_path = r''\n",
    "stem_base_path = r''\n",
    "out_path = r''\n",
    "calibration_factors = dict([('leaf_dataset1', 0.13715), ('leaf_dataset2', 0.14690)])  # Was 0.13888 for DS1 and 0.15698 for DS2\n",
    "# Pot 1 area manually segmented from Go-0/rep_08/1000334_2022_05_13_12_01_41-6-3-TC03-RGB1_pot_A2_Go-0-08.png\n",
    "# Pot 2 area manually segmented from Ler-1/rep_30/1000711_2022_08_09_17_01_44-7-29-TC06-RGB1_pot_D3_Ler-1-30.png\n",
    "pot_areas_calibrated = dict(\n",
    "    [('leaf_dataset1', 238177 * calibration_factors['leaf_dataset1'] * calibration_factors['leaf_dataset1']),\n",
    "     ('leaf_dataset2', 151381 * calibration_factors['leaf_dataset2'] * calibration_factors['leaf_dataset2'])])\n",
    "parallelize = True\n",
    "leaf_seq_in_path = False\n",
    "prefix_column_list = ['Date', 'Time', 'DAS', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "leaf_column_list = ['l_area (mm^2)',\n",
    "                    'l_perimeter (mm)',\n",
    "                    'l_roundness', 'l_circumference (mm)', 'l_eccentricity', 'l_compactness',\n",
    "                    'l_extent',\n",
    "                    'l_surface_coverage', 'l_RMA',\n",
    "                    'l_angle (deg)', 'l_length (mm)', 'l_lamina_length (mm)', 'l_petiole_length (mm)', 'l_width (mm)',\n",
    "                    'SOL', 'l_overlapping (%)']\n",
    "plant_column_list = ['Date', 'Time', 'DAS', 'Accession', 'Rep_num', 'Isotropy', 'LAI', 'SOL']\n",
    "Rep_Leaf_Traits_AVG_col_translations = dict(\n",
    "    [('l_area (mm^2)', 'l_area_AVG (mm^2)'),\n",
    "     ('l_perimeter (mm)', 'l_perimeter_AVG (mm)'),\n",
    "     ('l_roundness', 'l_roundness_AVG'),\n",
    "     ('l_circumference (mm)', 'l_circumference_AVG (mm)'),\n",
    "     ('l_eccentricity', 'l_eccentricity_AVG'),\n",
    "     ('l_compactness', 'l_compactness_AVG'),\n",
    "     ('l_extent', 'l_extent_AVG'),\n",
    "     ('l_length (mm)', 'l_length_AVG (mm)'),\n",
    "     ('l_width (mm)', 'l_width_AVG (mm)'),\n",
    "     ('l_RMA', 'l_RMA_AVG'),\n",
    "     ('l_overlapping (%)', 'l_overlapping_AVG (%)'),\n",
    "     ('SOL', 'SOL_AVG')])\n",
    "Accession_Leaf_Traits_col_translations = dict(\n",
    "    [('l_area (mm^2)', 'l_area_AVG (mm^2)'),\n",
    "     ('l_perimeter (mm)', 'l_perimeter_AVG (mm)'),\n",
    "     ('l_roundness', 'l_roundness_AVG'),\n",
    "     ('l_circumference (mm)', 'l_circumference_AVG (mm)'),\n",
    "     ('l_eccentricity', 'l_eccentricity_AVG'),\n",
    "     ('l_compactness', 'l_compactness_AVG'),\n",
    "     ('l_extent', 'l_extent_AVG'),\n",
    "     ('l_length (mm)', 'l_length_AVG (mm)'),\n",
    "     ('l_width (mm)', 'l_width_AVG (mm)'),\n",
    "     ('l_RMA', 'l_RMA_AVG'),\n",
    "     ('l_overlapping (%)', 'l_overlapping_AVG (%)'),\n",
    "     ('SOL', 'SOL_AVG')])\n",
    "\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print('Complete datasets with cropped and visible leaves...')\n",
    "for dataset in get_all_folders(leaf_base_path, only_foldernames=True, sorted_list=True):\n",
    "    print(f'> Dataset: \"{dataset}\"')\n",
    "    makedirs(join(out_path, dataset, 'Excels'))\n",
    "    ds_leaf_mask_profiles = []\n",
    "    ds_plant_traits = []\n",
    "    ds_df_list = []\n",
    "    ds_sheet_name_list = []\n",
    "    all_leaf_day_diff_per_rep = dict()\n",
    "    all_leaf_day_das_per_rep = dict()\n",
    "    for acc in get_all_folders(join(leaf_base_path, dataset), only_foldernames=True, sorted_list=True):\n",
    "        print(f'\\t>>> Accession: \"{acc}\"')\n",
    "        makedirs(join(out_path, dataset, 'Excels', acc))\n",
    "        init_acc_leaf_mask_profiles = []\n",
    "        init_acc_plant_traits = []\n",
    "        all_rep_folders = get_all_folders(join(leaf_base_path, dataset, acc), only_foldernames=True, sorted_list=True)\n",
    "        if len(all_rep_folders) == 0:\n",
    "            print('\\t\\t\\t----------------- No rep folders!!!! -----------------')\n",
    "        if parallelize:\n",
    "            results = Parallel(n_jobs=-2)(\n",
    "                delayed(compute_leaf_traits___per_rep)(leaf_base_path, dataset, acc, rep,\n",
    "                                                       stem_base_path, leaf_seq_in_path,\n",
    "                                                       leaf_column_list,\n",
    "                                                       pot_areas_calibrated[dataset], calibration_factors[dataset],\n",
    "                                                       parallelize) \n",
    "                for rep in all_rep_folders)\n",
    "            for rep_leaf_mask_profiles, rep_plant_traits, leaf_day_diff_per_rep, leaf_day_das_per_rep in results:\n",
    "                init_acc_leaf_mask_profiles.extend(rep_leaf_mask_profiles)\n",
    "                init_acc_plant_traits.extend(rep_plant_traits)\n",
    "                all_leaf_day_diff_per_rep.update(leaf_day_diff_per_rep)\n",
    "                all_leaf_day_das_per_rep.update(leaf_day_das_per_rep)\n",
    "        else:\n",
    "            for rep in all_rep_folders:\n",
    "                print(f'\\t\\t>>>>> Rep: \"{rep}\"')\n",
    "                rep_leaf_mask_profiles, \\\n",
    "                rep_plant_traits, \\\n",
    "                leaf_day_diff_per_rep, \\\n",
    "                leaf_day_das_per_rep = \\\n",
    "                    compute_leaf_traits___per_rep(\n",
    "                        leaf_base_path, dataset, acc, rep,\n",
    "                        stem_base_path, leaf_seq_in_path,\n",
    "                        leaf_column_list,\n",
    "                        pot_areas_calibrated[dataset], calibration_factors[dataset],\n",
    "                        parallelize)\n",
    "                init_acc_leaf_mask_profiles.extend(rep_leaf_mask_profiles)\n",
    "                init_acc_plant_traits.extend(rep_plant_traits)\n",
    "                all_leaf_day_diff_per_rep.update(leaf_day_diff_per_rep)\n",
    "                all_leaf_day_das_per_rep.update(leaf_day_das_per_rep)\n",
    "        ################################\n",
    "        # Save per accession           #\n",
    "        ################################\n",
    "        acc_df_list = []\n",
    "        # \"Leaf_Traits\" sheet\n",
    "        acc_sheet_name_list = []\n",
    "        if len(init_acc_leaf_mask_profiles) == 0:\n",
    "            print('ERROR: init_acc_leaf_mask_profiles is empty!')\n",
    "        else:\n",
    "            acc_leaf_mask_profiles = shift_dates(init_acc_leaf_mask_profiles, dataset, all_leaf_day_diff_per_rep, all_leaf_day_das_per_rep)\n",
    "            acc_df_leaf_traits = pd.DataFrame(sorted(acc_leaf_mask_profiles, key=lambda x: (x[3], x[4], x[5], x[0], x[1])),\n",
    "                                              columns=prefix_column_list + leaf_column_list)\n",
    "            acc_df_list.append(acc_df_leaf_traits)\n",
    "            acc_sheet_name_list.append('Leaf_Traits')\n",
    "        \n",
    "        # \"Plant_Traits\" sheet\n",
    "        if len(init_acc_plant_traits) == 0:\n",
    "            print('ERROR: init_acc_plant_traits is empty!')\n",
    "        else:\n",
    "            acc_plant_traits = shift_dates(init_acc_plant_traits, dataset, all_leaf_day_diff_per_rep, all_leaf_day_das_per_rep)\n",
    "            acc_df_plant_traits = pd.DataFrame(sorted(acc_plant_traits, key=lambda x: (x[3], x[4], x[0], x[1])),\n",
    "                                               columns=plant_column_list)\n",
    "            acc_df_list.append(acc_df_plant_traits)\n",
    "            acc_sheet_name_list.append('Plant_Traits')\n",
    "        \n",
    "        # \"Rep_Leaf_Traits_AVG\" sheet\n",
    "        acc_df_rep_leaf_traits_AVG_source = \\\n",
    "            acc_df_leaf_traits[[prefix_column_list[x] for x in [0, 3, 4, 5]]  # ['Date', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                               + list(Rep_Leaf_Traits_AVG_col_translations.keys())].groupby(\n",
    "            ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "            as_index=False).mean().round(3)\n",
    "        acc_df_rep_leaf_traits_AVG = acc_df_rep_leaf_traits_AVG_source[\n",
    "            [col for col in acc_df_rep_leaf_traits_AVG_source if col not in ['Date']]].groupby(\n",
    "            ['Accession', 'Rep_num', 'Leaf_num'],\n",
    "            as_index=False).mean().round(3)\n",
    "        acc_df_rep_leaf_traits_AVG.rename(columns=Rep_Leaf_Traits_AVG_col_translations, inplace=True)\n",
    "        acc_df_rep_leaf_traits_AVG.sort_values(['Accession', 'Rep_num', 'Leaf_num'], inplace=True)\n",
    "#         print(acc_df_rep_leaf_traits_AVG)\n",
    "        if acc_df_rep_leaf_traits_AVG.shape[0] == 0:\n",
    "            print('ERROR: acc_df_rep_leaf_traits_AVG is empty!')\n",
    "        else:\n",
    "            acc_df_list.append(acc_df_rep_leaf_traits_AVG)\n",
    "            acc_sheet_name_list.append('Rep_Leaf_Traits_AVG')\n",
    "        \n",
    "        acc_df_acc_leaf_traits_AVG_source = \\\n",
    "            acc_df_leaf_traits[[prefix_column_list[x] for x in [0, 2, 3, 4, 5]]  # ['Date', 'DAS', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                               + list(Accession_Leaf_Traits_col_translations.keys())].groupby(\n",
    "            ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "            as_index=False).mean().round(3)\n",
    "        acc_df_acc_leaf_traits_AVG = acc_df_acc_leaf_traits_AVG_source[\n",
    "            [col for col in acc_df_acc_leaf_traits_AVG_source if col not in ['Rep_num']]].groupby(\n",
    "            ['Date', 'Accession', 'Leaf_num'],\n",
    "            as_index=False).mean().round(3)\n",
    "        acc_df_acc_leaf_traits_AVG.rename(columns=Accession_Leaf_Traits_col_translations, inplace=True)\n",
    "        acc_df_acc_leaf_traits_AVG = acc_df_acc_leaf_traits_AVG[\n",
    "            ['Date', 'DAS', 'Accession', 'Leaf_num']\n",
    "            + [col for col in acc_df_acc_leaf_traits_AVG if col not in ['Date', 'DAS', 'Accession', 'Leaf_num']]]\n",
    "        acc_df_acc_leaf_traits_AVG.sort_values(['Accession', 'Leaf_num', 'Date'], inplace=True)\n",
    "        if acc_df_acc_leaf_traits_AVG.shape[0] == 0:\n",
    "            print('ERROR: acc_df_acc_leaf_traits_AVG is empty!')\n",
    "        else:\n",
    "            acc_df_list.append(acc_df_acc_leaf_traits_AVG)\n",
    "            acc_sheet_name_list.append('Accession_Leaf_Traits_AVG')\n",
    "\n",
    "        # Save to Excel\n",
    "        save_to_excel(acc_df_list, acc_sheet_name_list, join(out_path, dataset, 'Excels', acc, acc + '.xlsx'))\n",
    "        \n",
    "        ds_leaf_mask_profiles.extend(acc_leaf_mask_profiles)\n",
    "        ds_plant_traits.extend(acc_plant_traits)\n",
    "        \n",
    "        ################################\n",
    "        # Save per replicate           #\n",
    "        ################################\n",
    "        # Now also save per rep\n",
    "        curr_rep_folders = ['rep_{:02d}'.format(x)\n",
    "                            for x in acc_df_leaf_traits.loc[acc_df_leaf_traits['Accession'] == acc]['Rep_num'].unique()]\n",
    "        for rep in curr_rep_folders:\n",
    "            makedirs(join(out_path, dataset, 'Excels', acc, rep))\n",
    "            rep_df_list = []\n",
    "            rep_sheet_name_list = []\n",
    "\n",
    "            # \"Leaf_Traits\" sheet\n",
    "            rep_df_leaf_traits = acc_df_leaf_traits.loc[acc_df_leaf_traits['Rep_num'] == int(rep[-2:])]\n",
    "            if rep_df_leaf_traits.shape[0] == 0:\n",
    "                print('ERROR: rep_df_leaf_traits is empty!')\n",
    "            else:\n",
    "                rep_df_list.append(rep_df_leaf_traits)\n",
    "                rep_sheet_name_list.append('Leaf_Traits')\n",
    "            \n",
    "            # \"Plant_Traits\" sheet\n",
    "            rep_df_plant_traits = acc_df_plant_traits.loc[acc_df_plant_traits['Rep_num'] == int(rep[-2:])]\n",
    "            if rep_df_plant_traits.shape[0] == 0:\n",
    "                print('ERROR: rep_plant_traits is empty!')\n",
    "            else:\n",
    "                rep_df_list.append(rep_df_plant_traits)\n",
    "                rep_sheet_name_list.append('Plant_Traits')\n",
    "            \n",
    "            # \"Rep_Leaf_Traits_AVG\" sheet\n",
    "            rep_df_rep_leaf_traits_AVG_source = \\\n",
    "                rep_df_leaf_traits[[prefix_column_list[x] for x in [0, 3, 4, 5]]  # ['Date', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                                   + list(Rep_Leaf_Traits_AVG_col_translations.keys())].groupby(\n",
    "                ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "                as_index=False).mean().round(3)\n",
    "            rep_df_rep_leaf_traits_AVG = rep_df_rep_leaf_traits_AVG_source[\n",
    "                [col for col in rep_df_rep_leaf_traits_AVG_source if col not in ['Date']]].groupby(\n",
    "                ['Accession', 'Rep_num', 'Leaf_num'],\n",
    "                as_index=False).mean().round(3)\n",
    "            rep_df_rep_leaf_traits_AVG.rename(columns=Rep_Leaf_Traits_AVG_col_translations, inplace=True)\n",
    "            rep_df_rep_leaf_traits_AVG.sort_values(['Accession', 'Rep_num', 'Leaf_num'], inplace=True)\n",
    "            if rep_df_rep_leaf_traits_AVG.shape[0] == 0:\n",
    "                print('ERROR: rep_df_rep_leaf_traits_AVG is empty!')\n",
    "            else:\n",
    "                rep_df_list.append(rep_df_rep_leaf_traits_AVG)\n",
    "                rep_sheet_name_list.append('Rep_Leaf_Traits_AVG')\n",
    "        \n",
    "            # \"Accession_Leaf_Traits\" sheet\n",
    "            rep_df_acc_leaf_traits_AVG_source = \\\n",
    "                rep_df_leaf_traits[[prefix_column_list[x] for x in [0, 2, 3, 4, 5]]  # ['Date', 'DAS', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                                   + list(Accession_Leaf_Traits_col_translations.keys())].groupby(\n",
    "                ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "                as_index=False).mean().round(3)\n",
    "            rep_df_acc_leaf_traits_AVG = rep_df_acc_leaf_traits_AVG_source[\n",
    "                [col for col in rep_df_acc_leaf_traits_AVG_source if col not in ['Rep_num']]].groupby(\n",
    "                ['Date', 'Accession', 'Leaf_num'],\n",
    "                as_index=False).mean().round(3)\n",
    "            rep_df_acc_leaf_traits_AVG.rename(columns=Accession_Leaf_Traits_col_translations, inplace=True)\n",
    "            rep_df_acc_leaf_traits_AVG = rep_df_acc_leaf_traits_AVG[\n",
    "                ['Date', 'DAS', 'Accession', 'Leaf_num']\n",
    "                + [col for col in rep_df_acc_leaf_traits_AVG if col not in ['Date', 'DAS', 'Accession', 'Leaf_num']]]\n",
    "            rep_df_acc_leaf_traits_AVG.sort_values(['Accession', 'Leaf_num', 'Date'], inplace=True)\n",
    "#             print(rep_df_acc_leaf_traits_AVG)\n",
    "            if rep_df_acc_leaf_traits_AVG.shape[0] == 0:\n",
    "                print('ERROR: rep_df_acc_leaf_traits_AVG is empty!')\n",
    "            else:\n",
    "                rep_df_list.append(rep_df_acc_leaf_traits_AVG)\n",
    "                rep_sheet_name_list.append('Accession_Leaf_Traits_AVG')\n",
    "            \n",
    "            # Save to Excel\n",
    "            save_to_excel(rep_df_list, rep_sheet_name_list, join(out_path, dataset, 'Excels', acc, rep, rep + '.xlsx'))\n",
    "#         break\n",
    "            \n",
    "    ################################\n",
    "    # Save per dataset             #\n",
    "    ################################\n",
    "    # \"Leaf_Traits\" sheet\n",
    "    if len(ds_leaf_mask_profiles) == 0:\n",
    "        print('ERROR: ds_leaf_mask_profiles is empty!')\n",
    "    else:\n",
    "        ds_df_leaf_traits = pd.DataFrame(sorted(ds_leaf_mask_profiles, key=lambda x: (x[3], x[4], x[5], x[0], x[1])),\n",
    "                                         columns=prefix_column_list + leaf_column_list)\n",
    "        ds_df_list.append(ds_df_leaf_traits)\n",
    "        ds_sheet_name_list.append('Leaf_Traits')\n",
    "\n",
    "    # \"Plant_Traits\" sheet\n",
    "    if len(ds_plant_traits) == 0:\n",
    "        print('ERROR: ds_plant_traits is empty!')\n",
    "    else:\n",
    "        ds_df_plant_traits = pd.DataFrame(sorted(ds_plant_traits, key=lambda x: (x[3], x[4], x[0], x[1])),\n",
    "                                          columns=plant_column_list)\n",
    "        ds_df_list.append(ds_df_plant_traits)\n",
    "        ds_sheet_name_list.append('Plant_Traits')\n",
    "        \n",
    "    # \"Rep_Leaf_Traits_AVG\" sheet\n",
    "    ds_df_rep_leaf_traits_AVG_source = \\\n",
    "        ds_df_leaf_traits[[prefix_column_list[x] for x in [0, 3, 4, 5]]  # ['Date', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                          + list(Rep_Leaf_Traits_AVG_col_translations.keys())].groupby(\n",
    "        ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "        as_index=False).mean().round(3)\n",
    "    ds_df_rep_leaf_traits_AVG = ds_df_rep_leaf_traits_AVG_source[\n",
    "        [col for col in ds_df_rep_leaf_traits_AVG_source if col not in ['Date']]].groupby(\n",
    "        ['Accession', 'Rep_num', 'Leaf_num'],\n",
    "        as_index=False).mean().round(3)\n",
    "    ds_df_rep_leaf_traits_AVG.rename(columns=Rep_Leaf_Traits_AVG_col_translations, inplace=True)\n",
    "    ds_df_rep_leaf_traits_AVG.sort_values(['Accession', 'Rep_num', 'Leaf_num'], inplace=True)\n",
    "    if ds_df_rep_leaf_traits_AVG.shape[0] == 0:\n",
    "        print('ERROR: ds_df_rep_leaf_traits_AVG is empty!')\n",
    "    else:\n",
    "        ds_df_list.append(ds_df_rep_leaf_traits_AVG)\n",
    "        ds_sheet_name_list.append('Rep_Leaf_Traits_AVG')\n",
    "        \n",
    "    # \"Accession_Leaf_Traits\" sheet\n",
    "    ds_df_acc_leaf_traits_AVG_source = \\\n",
    "        ds_df_leaf_traits[[prefix_column_list[x] for x in [0, 2, 3, 4, 5]]  # ['Date', 'DAS', 'Accession', 'Rep_num', 'Leaf_num']\n",
    "                          + list(Accession_Leaf_Traits_col_translations.keys())].groupby(\n",
    "        ['Date', 'Accession', 'Rep_num', 'Leaf_num'],\n",
    "        as_index=False).mean().round(3)\n",
    "    ds_df_acc_leaf_traits_AVG = ds_df_acc_leaf_traits_AVG_source[\n",
    "        [col for col in ds_df_acc_leaf_traits_AVG_source if col not in ['Rep_num']]].groupby(\n",
    "        ['Date', 'Accession', 'Leaf_num'],\n",
    "        as_index=False).mean().round(3)\n",
    "    ds_df_acc_leaf_traits_AVG.rename(columns=Accession_Leaf_Traits_col_translations, inplace=True)\n",
    "    ds_df_acc_leaf_traits_AVG = ds_df_acc_leaf_traits_AVG[\n",
    "        ['Date', 'DAS', 'Accession', 'Leaf_num']\n",
    "        + [col for col in ds_df_acc_leaf_traits_AVG if col not in ['Date', 'DAS', 'Accession', 'Leaf_num']]]\n",
    "\n",
    "    ds_df_acc_leaf_traits_AVG.sort_values(['Accession', 'Leaf_num', 'Date'], inplace=True)\n",
    "    if ds_df_acc_leaf_traits_AVG.shape[0] == 0:\n",
    "        print('ERROR: ds_df_acc_leaf_traits_AVG is empty!')\n",
    "    else:\n",
    "        ds_df_list.append(ds_df_acc_leaf_traits_AVG)\n",
    "        ds_sheet_name_list.append('Accession_Leaf_Traits_AVG')\n",
    "\n",
    "    # Save to Excel\n",
    "    save_to_excel(ds_df_list, ds_sheet_name_list, join(out_path, dataset, 'Excels', 'Excel_ALL.xlsx'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
