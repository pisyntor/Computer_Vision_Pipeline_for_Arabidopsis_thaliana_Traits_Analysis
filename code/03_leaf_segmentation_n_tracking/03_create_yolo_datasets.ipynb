{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c7c928",
   "metadata": {},
   "source": [
    "# Create datasets for training/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_ROOT = (\n",
    "    \"\"  # root folder with images\n",
    ")\n",
    "MASKS_ROOT = (\n",
    "    \"\"  # root folder with labels\n",
    ")\n",
    "SEG_DS_SAVE_PATH = \"../data/yolo_train\"  # folder to save the segmentation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9c0c8",
   "metadata": {},
   "source": [
    "### Imports/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568586a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import (\n",
    "    build_dataset,\n",
    "    save_dataset,\n",
    "    load_dataset,\n",
    "    DEFAULT_DS_PATH,\n",
    ")\n",
    "\n",
    "from saveload import read_image, read_masks\n",
    "from masks import draw_joined_masks_on_image, mask_joined_to_masks_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14230373",
   "metadata": {},
   "source": [
    "### 1. Prepare ds file, split train/val/test if not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pathlib.Path(DEFAULT_DS_PATH).exists():\n",
    "    ds = load_dataset(images_root=IMAGES_ROOT, masks_root=MASKS_ROOT)\n",
    "    print(f\"Loaded dataset {DEFAULT_DS_PATH} with {len(ds)} items\")\n",
    "    ds.sample(5)\n",
    "    for _, r in ds.iterrows():\n",
    "        assert pathlib.Path(\n",
    "            r.image_path\n",
    "        ).exists(), f\"Path {r.image_path} does not exist\"\n",
    "        assert pathlib.Path(r.mask_path).exists(), f\"Path {r.mask_path} does not exist\"\n",
    "\n",
    "else:\n",
    "    print(f\"Building dataset {DEFAULT_DS_PATH}\")\n",
    "\n",
    "    ds = build_dataset(IMAGES_ROOT, MASKS_ROOT)\n",
    "    save_dataset(ds, DEFAULT_DS_PATH, IMAGES_ROOT, MASKS_ROOT)\n",
    "\n",
    "    # check\n",
    "    loaded_ds = load_dataset(DEFAULT_DS_PATH, IMAGES_ROOT, MASKS_ROOT)\n",
    "    assert ds.equals(loaded_ds)\n",
    "\n",
    "    display(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b423c",
   "metadata": {},
   "source": [
    "##### Calculate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8944eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images in each role\n",
    "for nn_role in [\"train\", \"val\", \"test\"]:\n",
    "    count = len(ds[ds[\"nn_role\"] == nn_role])\n",
    "    share = count / len(ds) * 100\n",
    "    print(f\"Number of {nn_role} images: {count} ({share:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sequences in each role\n",
    "for nn_role in [\"train\", \"val\", \"test\"]:\n",
    "    ds_role = ds[ds[\"nn_role\"] == nn_role]\n",
    "    ngroups = ds_role.groupby([\"plant\", \"rep\"]).ngroups\n",
    "    ratio = len(ds_role) / ngroups\n",
    "\n",
    "    print(\n",
    "        f\"Number of sequences in {nn_role}: {ngroups} ({ratio:.2f} avg. images per sequence)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e557e3-8d1e-485d-bd21-0f6bf8af9b5b",
   "metadata": {},
   "source": [
    "### 2. Resave train/val data to local files for YOLO segmentation network training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c463c-8703-431c-8a3d-aa6dc5c9f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = pathlib.Path(SEG_DS_SAVE_PATH)\n",
    "assert not os.path.exists(out_path), \"Output path already exists\"\n",
    "USE_ID = 0  # class id for the leaf\n",
    "\n",
    "\n",
    "class ContoursExtractor:\n",
    "    def __init__(self, erosion=5):\n",
    "        self.erosion = erosion\n",
    "        self.kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erosion, erosion))\n",
    "\n",
    "    def get_biggest_contour(self, mask):\n",
    "        # join parts of leaf in case some stem is visible upon the mask,\n",
    "        #    and that splits it to several parts\n",
    "        mask = cv2.dilate(mask.astype(np.uint8), self.kernel, iterations=1)\n",
    "        mask = cv2.erode(mask.astype(np.uint8), self.kernel, iterations=1)\n",
    "\n",
    "        contours, _ = cv2.findContours(\n",
    "            mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "\n",
    "        if len(contours) == 0:\n",
    "            raise ValueError(\"No contours found\")\n",
    "\n",
    "        return max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "## load dataset\n",
    "ds = load_dataset(DEFAULT_DS_PATH, IMAGES_ROOT, MASKS_ROOT)\n",
    "ds = ds[ds[\"nn_role\"].isin([\"train\", \"val\"])]\n",
    "contours_extractor = ContoursExtractor()\n",
    "\n",
    "for i, row in tqdm(ds.iterrows(), total=len(ds)):\n",
    "    image = read_image(row)\n",
    "    masks = read_masks(row)\n",
    "\n",
    "    image_output_path = (\n",
    "        out_path\n",
    "        / \"images\"\n",
    "        / row[\"nn_role\"]\n",
    "        / row[\"plant\"]\n",
    "        / row[\"rep\"]\n",
    "        / pathlib.Path(row[\"image_path\"]).name\n",
    "    )\n",
    "    os.makedirs(image_output_path.parent, exist_ok=True)\n",
    "    shutil.copy(row[\"image_path\"], image_output_path)\n",
    "\n",
    "    label_output_path = (\n",
    "        out_path\n",
    "        / \"labels\"\n",
    "        / row[\"nn_role\"]\n",
    "        / row[\"plant\"]\n",
    "        / row[\"rep\"]\n",
    "        / (pathlib.Path(row[\"image_path\"]).name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "    )\n",
    "    os.makedirs(label_output_path.parent, exist_ok=True)\n",
    "\n",
    "    with open(label_output_path, \"w\") as f:\n",
    "        for m in masks.values():\n",
    "            mask = m[\"segmentation\"]\n",
    "            imgwidth, imgheight = mask.shape[1], mask.shape[0]\n",
    "            contour = contours_extractor.get_biggest_contour(mask)\n",
    "\n",
    "            main_contour_str = (\n",
    "                f\"{USE_ID} \"\n",
    "                + \" \".join(f\"{x/imgwidth} {y/imgheight}\" for (x, y) in contour[:, 0, :])\n",
    "                + \"\\n\"\n",
    "            )\n",
    "            f.write(main_contour_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098dc4f-21e0-445c-be05-8b716a686107",
   "metadata": {},
   "source": [
    "##### Save dataset paths\n",
    "with global paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbeee4-d143-44ef-b84b-89b3bc40012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path('../data/yolo_train')\n",
    "p.absolute().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57b006-0873-4436-9ba4-f6a1597bca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultralytics YOLO dataset format\n",
    "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "dataset_paths = { \n",
    "    \"path\": str(pathlib.Path(SEG_DS_SAVE_PATH).absolute().resolve()), # dataset root dir\n",
    "    \"train\": \"images/train\", # train images (relative to 'path')\n",
    "    \"val\": \"images/val\", # val images (relative to 'path')\n",
    "\n",
    "    # Classes\n",
    "    \"names\": {0: \"leaf\"},\n",
    "}\n",
    "\n",
    "with open('../data_meta/yolo_train_ds.yaml', 'w') as f: \n",
    "    yaml.dump(dataset_paths, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3ceda",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "View a random saved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586275ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(out_path.glob(\"images/train/*/*/*.png\"))\n",
    "img_path = str(random.choice(images))\n",
    "mask_path = img_path.replace(\"images\", \"labels\").replace(\".png\", \".txt\")\n",
    "img = read_image({\"image_path\": img_path})\n",
    "with open(mask_path, \"r\") as f:\n",
    "    mask_lines = f.readlines()\n",
    "\n",
    "masks = {}\n",
    "for i, l in enumerate(mask_lines):\n",
    "    parts = l.strip().split(\" \")[1:]\n",
    "    nums = list(map(float, l.strip().split(\" \")[1:]))\n",
    "    contour = np.array(\n",
    "        [(x * img.shape[1], y * img.shape[0]) for (x, y) in zip(nums[::2], nums[1::2])]\n",
    "    )\n",
    "    b_mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    contour = contour.astype(np.int32)\n",
    "    contour = contour.reshape(-1, 1, 2)\n",
    "    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masks[i] = {\"segmentation\": b_mask > 0}\n",
    "plt.imshow(draw_joined_masks_on_image(img, masks, not_on_image=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
